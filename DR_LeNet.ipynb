{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ba3207",
   "metadata": {},
   "source": [
    "# Digit Recognizer - Image Classification with a LeNet Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017e779",
   "metadata": {},
   "source": [
    "The objective of this Kaggle competition is to build and train a Neural Network for image classification; the dataset is composed by image in grayscale representing hand written digits from 0 to 9 which have to be correctly labeled. For this competition I am planning to build, train and test different architectures for image classification: in particular, the LeNet neural network will be implemented; first, the original architecture is gonna be tested, then optuna will be used to perform hyperparameters optimization while maintaining the original architecture; in conclusion, the performances of the two approaches will be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d8225",
   "metadata": {},
   "source": [
    "Let us set the autoreloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1f222",
   "metadata": {},
   "source": [
    "Let us set up tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f3d09",
   "metadata": {},
   "source": [
    "Let us import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preliminary.preprocess import show_image, create_dataset\n",
    "from models.LeNet import LeNet_optimize, LeNet_predict, LeNet, LeNet_performance, plot_history\n",
    "from models.LeNet_ensemble import LeNet_ensemble_performance, LeNet_ensemble_predict, plot_history_ensemble\n",
    "from models.learning_curve import learning_curve, learning_curve_ensemble, plot_learning_curve\n",
    "from utilities import generate_submission_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a30df",
   "metadata": {},
   "source": [
    "Let us load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(\"train.csv\").to_numpy()\n",
    "dataset_test = pd.read_csv(\"test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108255b",
   "metadata": {},
   "source": [
    "The dataset is composed by images of size 28x28, which can be easily plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 1\n",
    "plot_size = (8,8)\n",
    "plot_code = \"show\"\n",
    "show_image(dataset_train, plot_code, image_index, plot_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 4\n",
    "plot_size = (8,8)\n",
    "plot_code = \"explore\"\n",
    "show_image(dataset_test, plot_code, image_index, plot_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1016d6",
   "metadata": {},
   "source": [
    "To feed the data to the Neural Networks that are gonna be trained it is necessary properly reshape the data into suitable numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(dataset_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = create_dataset(dataset_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb36af1",
   "metadata": {},
   "source": [
    "Now it is possible to create the dictionaries for training the neural network and for using it to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1385c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(X_train, y_train, test_size=0.4)\n",
    "X_val_eval, X_test_eval, y_val_eval, y_test_eval = train_test_split(X_test_eval, y_test_eval, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_eval = {\"train\": [X_train_eval, y_train_eval], \"val\": [X_val_eval, y_val_eval], \"test_eval\": [X_test_eval, y_test_eval]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pred, X_val_pred, y_train_pred, y_val_pred = train_test_split(X_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_pred = {\"train\": [X_train_pred, y_train_pred], \"val\": [X_val_pred, y_val_pred], \"test\": X_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bbece",
   "metadata": {},
   "source": [
    "### Legacy LeNet Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08838e01",
   "metadata": {},
   "source": [
    "Let us implement a version of theLeNet neural network similar to the original one: the flattening layer before the classification head can be replaced by a global average pooling layer, so that the total number of parameters can be reduced. The parameters of this simplified LeNet neural network are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20471929",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_params_original = {\n",
    "    \"kernel size 1\": 5,\n",
    "    \"kernel size 2\": 5,\n",
    "    \"n filter 1\": 6,\n",
    "    \"n filter 2\": 16,\n",
    "    \"activation function conv\": \"tanh\",\n",
    "    \"l2 regularizer conv\": 0,\n",
    "    \"pool size 1\": 2,\n",
    "    \"pool size 2\": 2,\n",
    "    \"dense size 1\": 120,\n",
    "    \"dense size 2\": 84,\n",
    "    \"activation function dense\": \"tanh\",\n",
    "    \"l2 regularizer dense\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8777335",
   "metadata": {},
   "source": [
    "The performances of the LeNet neural network can be established by evaluating different metrics, like the accuracy, the confusion matrix and the ROC AUC scores. To compute these quantities it is possible to train the LeNet network multiple times and then evaluates its performances on the data, so that average values and standard deviations can be easily computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27491b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "n_samples = 10\n",
    "results_original = LeNet_performance(datasets_eval, LeNet_params_original, batch_size, epochs, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26662f97",
   "metadata": {},
   "source": [
    "The performances of the original LeNet neural network are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train accuracy - avg: {np.round(results_original['accuracy']['train'][0], decimals=3)}, std: {np.round(results_original['accuracy']['train'][1], decimals=3)}\")\n",
    "print(f\"val accuracy - avg: {np.round(results_original['accuracy']['val'][0], decimals=3)}, std: {np.round(results_original['accuracy']['val'][1], decimals=3)}\")\n",
    "print(f\"test accuracy - avg: {np.round(results_original['accuracy']['test'][0], decimals=3)}, std: {np.round(results_original['accuracy']['test'][1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27de648",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(10):\n",
    "    print(f\"roc auc score of class {c} (one vs rest appraoch) - avg: {np.round(results_original['roc auc']['mean'][c], decimals=4)}, std: {np.round(results_original['roc auc']['std'][c], decimals=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd62009",
   "metadata": {},
   "source": [
    "It is also possible to compute the learning curve for the standard LeNet neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ff465",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_sizes = np.array([0.01, 0.02, 0.03,0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])\n",
    "n_samples = 20\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "train_acc_avg_original, test_acc_avg_original, train_acc_std_original, test_acc_std_original = learning_curve(training_set_sizes, datasets_eval, n_samples, LeNet_params_original, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3447f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = (8,8)\n",
    "classifier_name = \"standard LeNet neural network\"\n",
    "plot_learning_curve(training_set_sizes, train_acc_avg_original, test_acc_avg_original, train_acc_std_original, test_acc_std_original, plot_size, classifier_name)\n",
    "#plt.savefig(\"standard_LeNet_learning_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"standard_LeNet_learning_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ec509",
   "metadata": {},
   "source": [
    "Now the neural network can be used to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 60\n",
    "log_dir = \"D://Codes//Python//Kaggle Competitions//Digit Recognizer//tensorboard_log//LeNet\"\n",
    "verbose = \"auto\"\n",
    "model_original = LeNet(LeNet_params_original)\n",
    "model_original, train_accuracy, val_accuracy, history, y_pred_original = LeNet_predict(datasets_pred, model_original, log_dir, batch_size, epochs, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd97a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train accuracy: {np.round(train_accuracy, decimals=3)}, val accuracy: {np.round(val_accuracy, decimals=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e813272",
   "metadata": {},
   "source": [
    "To check the convergence of the LeNet neural network used to maked predictions, it is possible to analyze the behaviour of the accuracy on the training set and on the validation set as a function of the epochs of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = (8,8)\n",
    "classifier_name = \"standard LeNet neural network\"\n",
    "plot_history(history, plot_size, classifier_name)\n",
    "#plt.savefig(\"standard_LeNet_convergence_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50313aac",
   "metadata": {},
   "source": [
    "The model summary for the original LeNet neural network is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709f172",
   "metadata": {},
   "source": [
    "The submission file for the original LeNet neural network can be produced, so that it is possible to establish a baseline to understand which model is better between the original one and the one obtained via hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission_file(dataset_test, y_pred_original, \"LeNet_baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7fe43",
   "metadata": {},
   "source": [
    "### Optimized LeNet Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ca39e",
   "metadata": {},
   "source": [
    "Let us now define the search space for the hyperparameters of the LeNet neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3780c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"kernel size 1\": [3, 5, 7],\n",
    "    \"kernel size 2\": [3, 5, 7],\n",
    "    \"n filter 1\": [3, 5, 7, 9, 11, 13],\n",
    "    \"n filter 2\": [3, 5, 7, 9, 11, 13],\n",
    "    \"activation function conv\": [\"sigmoid\", \"relu\", \"gelu\", \"elu\", \"tanh\"],\n",
    "    \"l2 regularizer conv\": [1e-6, 1e-2],\n",
    "    \"pool size 1\": [2, 4],\n",
    "    \"pool size 2\": [2, 4],\n",
    "    \"dense size 1\": [32, 64, 128, 256],\n",
    "    \"dense size 2\": [32, 64, 128, 256],\n",
    "    \"activation function dense\": [\"sigmoid\", \"relu\", \"gelu\", \"elu\", \"tanh\"],\n",
    "    \"l2 regularizer dense\": [1e-6, 1e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd6ee2",
   "metadata": {},
   "source": [
    "Let us now find the set of the optimal parameters of the LeNet neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80970b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "n_trial = 200\n",
    "verbose = \"auto\"\n",
    "storage_url = \"sqlite:///optuna_study.db\"\n",
    "study = LeNet_optimize(datasets_eval, search_space, batch_size, epochs, n_trial, f\"{str(datetime.datetime.today())[:-10]} - LeNet\", verbose, storage_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e844037",
   "metadata": {},
   "source": [
    "The results of the optimization procedure can be displayed; in particular, it is possible to plot the importance of the hyperparameters, the intermediate values of the objective function for the different trials and the optimization history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba762be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study, target_name=\"Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8586645",
   "metadata": {},
   "source": [
    "In a way analogous to what has already been done with the standard LeNet neural network, the performances of the optimized LeNet neural network can be evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "n_samples = 10\n",
    "results = LeNet_performance(datasets_eval, study.best_params, batch_size, epochs, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bfaa2",
   "metadata": {},
   "source": [
    "The performances of the LeNet neural network with hyperparameters optimization are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train accuracy - avg: {np.round(results['accuracy']['train'][0], decimals=3)}, std: {np.round(results['accuracy']['train'][1], decimals=3)}\")\n",
    "print(f\"val accuracy - avg: {np.round(results['accuracy']['val'][0], decimals=3)}, std: {np.round(results['accuracy']['val'][1], decimals=3)}\")\n",
    "print(f\"test accuracy - avg: {np.round(results['accuracy']['test'][0], decimals=3)}, std: {np.round(results['accuracy']['test'][1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ec26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(10):\n",
    "    print(f\"roc auc score of class {c} (one vs rest appraoch) - avg: {np.round(results['roc auc']['mean'][c], decimals=4)}, std: {np.round(results['roc auc']['std'][c], decimals=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb11c4d",
   "metadata": {},
   "source": [
    "It is also possible to compute the learning curve for the optimized LeNet neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6274e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_sizes = np.array([0.01, 0.02, 0.03,0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])\n",
    "n_samples = 20\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "train_acc_avg_optimized, test_acc_avg_optimized, train_acc_std_optimized, test_acc_std_optimized = learning_curve(training_set_sizes, datasets_eval, n_samples, study.best_params, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = (8,8)\n",
    "classifier_name = \"optimized LeNet neural network\"\n",
    "plot_learning_curve(training_set_sizes, train_acc_avg_optimized, test_acc_avg_optimized, train_acc_std_optimized, test_acc_std_optimized, plot_size, classifier_name)\n",
    "#plt.savefig(\"optimized_LeNet_learning_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74cdd1",
   "metadata": {},
   "source": [
    "Now it is possible to use the optimal set of hyperparameters to train a LeNet neural network and use it for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37933bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 60\n",
    "log_dir = \"D://Codes//Python//Kaggle Competitions//Digit Recognizer//tensorboard_log//LeNet\"\n",
    "verbose = \"auto\"\n",
    "model = LeNet(study.best_params)\n",
    "model, train_accuracy, val_accuracy, history_optimized, y_pred = LeNet_predict(datasets_pred, model, log_dir, batch_size, epochs, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434086d",
   "metadata": {},
   "source": [
    "To check the convergence of the optimized LeNet neural network used to maked predictions, it is possible to analyze the behaviour of the accuracy on the training set and on the validation set as a function of the epochs of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = (8,8)\n",
    "classifier_name = \"optimized LeNet neural network\"\n",
    "plot_history(history_optimized, plot_size, classifier_name)\n",
    "#plt.savefig(\"optimized_LeNet_convergence_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b29a4",
   "metadata": {},
   "source": [
    "The architecture of the trained neural network can be plotted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113768b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=\"LeNet_1\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ca929",
   "metadata": {},
   "source": [
    "The model summary is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc8e06",
   "metadata": {},
   "source": [
    "Now it is possible to show the images in the test set together with their predicted label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 67\n",
    "plot_size = (8,8)\n",
    "dataset_code = \"predict\"\n",
    "predicted_label = np.argmax(y_pred[image_index,:])\n",
    "show_image(dataset_test, dataset_code, image_index, plot_size, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827fdbb",
   "metadata": {},
   "source": [
    "The output file for submission can be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission_file(dataset_test, y_pred, \"LeNet_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a75141",
   "metadata": {},
   "source": [
    "### Deep Ensemble with LeNet neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728dbb6",
   "metadata": {},
   "source": [
    "To obtain a better model, it is possible to build an ensemble of LeNet neural networks. To do this, let us consider the same architecture and the same set of hyperparameters, then, each model in the ensemble can be trained on the same dataset. The hyperparameters of each member of the ensemble can be set equal to the optimal ones obtained before. The performances of the ensemble can be tested with an approach analogous to the one used to evaluate a single network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacb310",
   "metadata": {},
   "source": [
    "Now it is possible to analyze in details the performances of the ensembles of the LeNet neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef99b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "n_samples = 10\n",
    "ensemble_size = 10\n",
    "results_ensemble = LeNet_ensemble_performance(datasets_eval, study.best_params, batch_size, epochs, n_samples, ensemble_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202a398",
   "metadata": {},
   "source": [
    "The performances of the ensemble of LeNet neural networks are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train accuracy - avg: {np.round(results_ensemble['accuracy']['train'][0], decimals=3)}, std: {np.round(results_ensemble['accuracy']['train'][1], decimals=3)}\")\n",
    "print(f\"val accuracy - avg: {np.round(results_ensemble['accuracy']['val'][0], decimals=3)}, std: {np.round(results_ensemble['accuracy']['val'][1], decimals=3)}\")\n",
    "print(f\"test accuracy - avg: {np.round(results_ensemble['accuracy']['test'][0], decimals=3)}, std: {np.round(results_ensemble['accuracy']['test'][1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(10):\n",
    "    print(f\"roc auc score of class {c} (one vs rest approach) - avg: {np.round(results_ensemble['roc auc']['mean'][c], decimals=5)}, std: {np.round(results_ensemble['roc auc']['std'][c], decimals=5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d261707",
   "metadata": {},
   "source": [
    "It is also possible to compute the learning curve for the ensemble of LeNet neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_sizes = np.array([0.01, 0.02, 0.03,0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])\n",
    "n_samples = 20\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "ensemble_size = 10\n",
    "train_acc_avg_ensemble, test_acc_avg_ensemble, train_acc_std_ensemble, test_acc_std_ensemble = learning_curve_ensemble(training_set_sizes, datasets_eval, n_samples, study.best_params, batch_size, epochs, ensemble_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6620132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = (8,8)\n",
    "classifier_name = \"ensemble of LeNet neural networks\"\n",
    "plot_learning_curve(training_set_sizes, train_acc_avg_ensemble, test_acc_avg_ensemble, train_acc_std_ensemble, test_acc_std_ensemble, plot_size, classifier_name)\n",
    "#plt.savefig(\"ensemble_LeNet_learning_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a125297",
   "metadata": {},
   "source": [
    "Now the ensemble can be used to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "ensemble_size = 10\n",
    "models = [LeNet(study.best_params) for _ in range(ensemble_size)]\n",
    "models, train_accuracy, val_accuracy, histories, y_pred_ensemble = LeNet_ensemble_predict(datasets_pred, models, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train accuracy: {train_accuracy}, val accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = (8,8)\n",
    "plot_history_ensemble(histories, plot_size)\n",
    "#plt.savefig(\"ensemble_LeNet_convergence_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8406de",
   "metadata": {},
   "source": [
    "The submission file for the ensemble of LeNet neural networks can be produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission_file(dataset_test, y_pred_ensemble, \"LeNet_ensemble.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
